
 â–â–›â–ˆâ–ˆâ–ˆâ–œâ–Œ   Claude Code v2.0.64
â–â–œâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–›â–˜  Opus 4.5 Â· Claude Max
  â–˜â–˜ â–â–    D:\dev\gabrieldechichi\programming-studies\wasm-multicore-demo

> /clear 
  â¿ Â (no content)

> read main.c, gpu.c and renderer.ts for context 

â— Search(pattern: "**/{main.c,gpu.c,renderer.ts}")
  â¿ Â Found 3 files (ctrl+o to expand)

â— Read(main.c)
  â¿ Â Read 190 lines

â— Read(gpu.c)
  â¿ Â Read 425 lines

â— Read(renderer.ts)
  â¿ Â Read 455 lines

> Explain the renderer to me in detail, explain everything that is done and 
everything that is going on. 

â— I've read all three files. Here's a detailed explanation of this
  multi-threaded WebGPU renderer:

  Architecture Overview

  This is a multi-threaded WebAssembly renderer that draws 1024 rotating
  cubes using WebGPU. The C code runs in WASM with multiple worker threads,
  while TypeScript handles the actual GPU API calls.

  ---
  C Side (main.c + gpu.c)

  Thread Model (main.c)

  Initialization (wasm_main):
  1. Initializes GPU and allocates 16MB arena from heap
  2. Creates 1024 cubes arranged in an 8x8 grid with different rotation
  rates
  3. Spawns N worker threads (based on processor count)
  4. Each thread gets a ThreadContext with its index, barrier reference, and
   temp arena

  Frame Loop (wasm_frame):
  Main Thread:
    1. Update time
    2. Set view/projection matrices
    3. Call renderer_begin_frame() - clears screen, resets command queue
    4. lane_sync() â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    5. app_update_and_render()      â”‚ All threads work in parallel
    6. lane_sync() â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    7. Call renderer_end_frame() - processes commands, issues GPU draws

  Worker Threads (loop forever):
    1. lane_sync() â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    2. app_update_and_render()      â”‚ Synchronized with main
    3. lane_sync() â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  Work Distribution (app_update_and_render):
  - lane_range(NUM_CUBES) divides cubes among threads
  - Each thread processes its range, building model matrices and calling
  renderer_draw_mesh()
  - Draw commands are appended to a lock-free concurrent array

  ---
  GPU Abstraction (gpu.c)

  Resource Management:
  - GpuBuffer, GpuShader, GpuPipeline are handles with idx + gen (generation
   for safety)
  - C functions like gpu_make_buffer() call JS imports (js_gpu_make_buffer)
  which return indices

  Dynamic Uniform Buffer (key optimization):
  GpuUniformBuffer {
    ArenaAllocator arena;  // CPU staging buffer (256-byte aligned)
    GpuBuffer gpu_buf;     // GPU buffer
  }
  - gpu_uniform_alloc() - allocates uniform slot, returns offset
  - gpu_uniform_flush() - single bulk upload to GPU at frame end
  - Uses 256-byte alignment for WebGPU dynamic offset requirements

  Renderer State:
  RendererState {
    vbuf, ibuf           // Shared cube mesh (24 vertices, 36 indices)
    shader, pipeline     // Single pipeline for all cubes
    uniforms             // Dynamic uniform buffer
    view, proj, view_proj // Per-frame matrices
    cmds                 // RenderCmd_ConcurrentArray (thread-safe)
  }

  Frame Flow:
  1. renderer_begin_frame() - resets command queue, clears GPU, stores
  view/proj
  2. renderer_draw_mesh() - appends RenderCmd with model matrix (atomic)
  3. renderer_end_frame():
    - Applies pipeline once
    - For each command: compute MVP, allocate uniform slot, draw
    - Flush all uniforms in single upload
    - Submit to GPU

  ---
  TypeScript Side (renderer.ts)

  Initialization

  createRenderer():
  1. Gets WebGPU adapter and device
  2. Configures canvas context
  3. Creates depth texture (depth24plus format)

  GPU Imports (WASM â†’ JS)

  These functions are called from C via WASM_IMPORT:

  | Function                      | Purpose
                     |
  |-------------------------------|-----------------------------------------
  -------------------|
  | js_gpu_make_buffer            | Creates vertex/index/uniform buffer
                     |
  | js_gpu_make_shader            | Compiles WGSL shader module
                     |
  | js_gpu_make_pipeline          | Creates render pipeline with vertex
  layout                 |
  | js_gpu_begin_pass             | Starts render pass with clear
  color/depth                  |
  | js_gpu_apply_pipeline         | Sets active pipeline
                     |
  | js_gpu_apply_bindings_dynamic | Sets vertex/index buffers + bind group
  with dynamic offset |
  | js_gpu_draw_indexed           | Issues indexed draw call
                     |
  | js_gpu_end_pass               | Ends render pass
                     |
  | js_gpu_upload_uniforms        | Bulk uploads uniform data
                     |
  | js_gpu_commit                 | Submits command buffer to GPU queue
                     |

  Key Implementation Details

  Pipeline Creation (js_gpu_make_pipeline):
  - Reads vertex layout from WASM memory (stride, attributes)
  - Creates GPUBindGroupLayout with hasDynamicOffset: true
  - Enables backface culling and depth testing

  Dynamic Uniform Binding (js_gpu_apply_bindings_dynamic):
  - Caches bind groups per pipeline+buffer combo
  - Uses setBindGroup(0, bindGroup, [uniformOffset]) for dynamic offsets
  - Uniform size fixed at 256 bytes (alignment requirement)

  ---
  Data Flow Diagram

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                        WASM (C Code)                            â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚  Thread 0 (Main)     Thread 1        Thread 2       Thread N   â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
  â”‚  â”‚begin_frame() â”‚   â”‚          â”‚   â”‚          â”‚   â”‚          â”‚ â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚          â”‚   â”‚          â”‚   â”‚          â”‚ â”‚
  â”‚         â”‚ barrier   â”‚ barrier  â”‚   â”‚ barrier  â”‚   â”‚ barrier  â”‚ â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
  â”‚  â”‚cubes 0-255   â”‚   â”‚cubes     â”‚   â”‚cubes     â”‚   â”‚cubes     â”‚ â”‚
  â”‚  â”‚draw_mesh()   â”‚   â”‚256-511   â”‚   â”‚512-767   â”‚   â”‚768-1023  â”‚ â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â”‚
  â”‚         â”‚                â”‚              â”‚              â”‚       â”‚
  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
  â”‚                          â”‚ (concurrent append to cmd queue)    â”‚
  â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
  â”‚                   â”‚ end_frame()  â”‚                             â”‚
  â”‚                   â”‚ - process    â”‚                             â”‚
  â”‚                   â”‚ - flush      â”‚                             â”‚
  â”‚                   â”‚ - commit     â”‚                             â”‚
  â”‚                   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ JS imports
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                    TypeScript (renderer.ts)                     â”‚
  â”‚  - Manages GPUDevice, GPUBuffer[], GPURenderPipeline[]         â”‚
  â”‚  - Executes WebGPU commands                                    â”‚
  â”‚  - Submits to GPU queue                                        â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  ---
  Performance Optimizations

  1. Multi-threaded command generation - All threads compute matrices in
  parallel
  2. Lock-free command queue - Atomic append avoids mutex contention
  3. Dynamic uniform buffer - Single allocation + single upload per frame
  instead of per-object
  4. Bind group caching - Reuses bind groups with dynamic offsets
  5. Single pipeline - All cubes share one pipeline, reducing state changes

â— Complete Renderer Explanation

  This is a multi-threaded WebAssembly renderer that draws 1024 rotating
  cubes using WebGPU. Let me walk through every component in detail.

  ---
  1. System Architecture

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                         Browser                                      â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
  â”‚  â”‚                    Main Thread (JS)                           â”‚   â”‚
  â”‚  â”‚  - Loads WASM module                                          â”‚   â”‚
  â”‚  â”‚  - Provides GPU imports                                       â”‚   â”‚
  â”‚  â”‚  - Owns WebGPU device/context                                 â”‚   â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
  â”‚                              â”‚                                       â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
  â”‚  â”‚              WASM Threads (SharedArrayBuffer)                 â”‚   â”‚
  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚   â”‚
  â”‚  â”‚  â”‚Thread 0 â”‚ â”‚Thread 1 â”‚ â”‚Thread 2 â”‚ â”‚Thread N â”‚             â”‚   â”‚
  â”‚  â”‚  â”‚ (main)  â”‚ â”‚(worker) â”‚ â”‚(worker) â”‚ â”‚(worker) â”‚             â”‚   â”‚
  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚   â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  ---
  2. Initialization (main.c:wasm_main)

  Step 1: GPU Initialization

  gpu_init();  // Calls js_gpu_init() - just logs "[GPU] Initialized"

  Step 2: Memory Setup

  u8 *heap = os_get_heap_base();
  ArenaAllocator arena = arena_from_buffer(heap, MB(16));
  - Gets the WASM heap base pointer
  - Creates a 16MB arena allocator for all allocations

  Step 3: Renderer Initialization (gpu.c:renderer_init)

  renderer_init(&arena);

  This creates all GPU resources:

  Vertex Buffer (24 vertices for a cube):
  g_renderer.vbuf = gpu_make_buffer(&(GpuBufferDesc){
      .type = GPU_BUFFER_VERTEX,
      .size = sizeof(cube_vertices),  // 24 * 28 bytes = 672 bytes
      .data = cube_vertices,
  });

  Each vertex has:
  - Position: f32 x, y, z (12 bytes)
  - Color: f32 r, g, b, a (16 bytes)
  - Total: 28 bytes per vertex

  The cube has 6 faces Ã— 4 vertices = 24 vertices, each face a different
  color (red, green, blue, yellow, magenta, cyan).

  Index Buffer (36 indices for 12 triangles):
  g_renderer.ibuf = gpu_make_buffer(&(GpuBufferDesc){
      .type = GPU_BUFFER_INDEX,
      .size = sizeof(cube_indices),  // 36 * 2 bytes = 72 bytes
      .data = cube_indices,
  });
  - 6 faces Ã— 2 triangles Ã— 3 indices = 36 indices
  - Using u16 format (2 bytes each)

  Dynamic Uniform Buffer:
  gpu_uniform_init(&g_renderer.uniforms, arena, GPU_UNIFORM_BUFFER_SIZE);

  This is critical for performance:
  void gpu_uniform_init(GpuUniformBuffer *ub, ArenaAllocator *parent_arena, 
  u32 size) {
      // Allocate 256-byte aligned staging buffer on CPU
      u8 *staging = arena_alloc_align(parent_arena, size, 256);
      ub->arena = arena_from_buffer(staging, size);

      // Create corresponding GPU buffer
      ub->gpu_buf = gpu_make_buffer(&(GpuBufferDesc){
          .type = GPU_BUFFER_UNIFORM,
          .size = size,
          .data = 0,  // No initial data
      });
  }

  Shader (WGSL):
  g_renderer.shader = gpu_make_shader(&(GpuShaderDesc){
      .vs_code = cube_vs,
      .fs_code = cube_fs,
  });

  Vertex shader:
  struct Uniforms {
      mvp: mat4x4<f32>,  // Model-View-Projection matrix
  };
  @group(0) @binding(0) var<uniform> uniforms: Uniforms;

  @vertex
  fn vs_main(in: VertexInput) -> VertexOutput {
      var out: VertexOutput;
      out.position = uniforms.mvp * vec4<f32>(in.position, 1.0);
      out.color = in.color;
      return out;
  }

  Fragment shader:
  @fragment
  fn fs_main(@location(0) color: vec4<f32>) -> @location(0) vec4<f32> {
      return color;  // Pass-through vertex color
  }

  Pipeline:
  g_renderer.pipeline = gpu_make_pipeline(&(GpuPipelineDesc){
      .shader = g_renderer.shader,
      .vertex_layout = {
          .stride = sizeof(CubeVertex),  // 28 bytes
          .attrs = {
              {GPU_VERTEX_FORMAT_FLOAT3, 0, 0},           // position at 
  offset 0
              {GPU_VERTEX_FORMAT_FLOAT4, offsetof(CubeVertex, r), 1},  // 
  color at offset 12
          },
          .attr_count = 2,
      },
      .primitive = GPU_PRIMITIVE_TRIANGLES,
      .depth_test = true,
      .depth_write = true,
  });

  Command Queue:
  g_renderer.cmds = (RenderCmd_ConcurrentArray){
      .len_atomic = 0,
      .cap = MAX_RENDER_CMDS,  // 1024
      .items = ARENA_ALLOC_ARRAY(arena, RenderCmd, MAX_RENDER_CMDS),
  };
  - Lock-free array for multi-threaded command submission
  - Uses atomic operations for thread-safe append

  Step 4: Cube Data Initialization

  void init_cubes(void) {
      u32 grid_size = 8;
      f32 spacing = 2.5f;
      f32 offset = (grid_size - 1) * spacing * 0.5f;  // Center the grid

      for (u32 i = 0; i < NUM_CUBES; i++) {
          u32 x = i % grid_size;
          u32 z = i / grid_size;

          cubes[i].position[0] = x * spacing - offset;
          cubes[i].position[1] = 0.0f;
          cubes[i].position[2] = z * spacing - offset;
          cubes[i].rotation_rate = 0.5f + (f32)i * 0.05f;  // Different 
  speeds
      }
  }

  Note: With 1024 cubes and grid_size=8, it's actually a floor(1024/8) = 128
   rows Ã— 8 columns grid.

  Step 5: Thread Spawning

  u8 NUM_WORKERS = os_get_processor_count();

  // Main thread context (thread 0)
  main_thread_ctx = (ThreadContext){
      .thread_idx = 0,
      .thread_count = NUM_WORKERS,
      .barrier = &frame_barrier,
      .temp_arena = arena_from_buffer(..., KB(64)),
  };
  tctx_set_current(&main_thread_ctx);

  // Spawn worker threads (1 to N-1)
  for (u8 i = 1; i < NUM_WORKERS; i++) {
      thread_contexts[i] = (ThreadContext){
          .thread_idx = i,
          .thread_count = NUM_WORKERS,
          .barrier = &frame_barrier,
          ...
      };
      threads[i] = thread_launch(worker_loop, &worker_data[i]);
  }

  Each thread knows:
  - Its index (thread_idx)
  - Total thread count (thread_count)
  - Shared barrier for synchronization
  - Its own temp arena (64KB)

  ---
  3. Frame Loop

  Main Thread (wasm_frame)

  void wasm_frame(void) {
      // 1. Update global time
      g_time += 0.016f;  // ~60fps assumption

      // 2. Setup camera matrices
      mat4 view, proj;
      glm_lookat((vec3){0, 15, 25}, (vec3){0, 0, 0}, (vec3){0, 1, 0}, view);
      glm_perspective(RAD(45.0f), 16.0f / 9.0f, 0.1f, 100.0f, proj);

      // 3. Begin frame (main thread only)
      if (is_main_thread()) {
          renderer_begin_frame(view, proj, (GpuColor){0.05f, 0.05f, 0.08f,
  1.0f});
      }

      // 4. BARRIER - release workers to start
      lane_sync();

      // 5. All threads (including main) process cubes
      app_update_and_render();

      // 6. BARRIER - wait for all threads to finish
      lane_sync();

      // 7. End frame (main thread only)
      if (is_main_thread()) {
          renderer_end_frame();
      }
  }

  Worker Threads (worker_loop)

  void worker_loop(void *arg) {
      WorkerData *data = (WorkerData *)arg;
      tctx_set_current(data->ctx);

      for (;;) {  // Infinite loop
          lane_sync();           // Wait for frame start
          app_update_and_render();  // Do work
          lane_sync();           // Signal completion
      }
  }

  Synchronization Timeline

  Time â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º

  Main:    [begin_frame] â”€â”€barrierâ”€â”€â–º [update] â”€â”€barrierâ”€â”€â–º [end_frame]
  Worker1:               â”€â”€barrierâ”€â”€â–º [update] â”€â”€barrierâ”€â”€â–º
  Worker2:               â”€â”€barrierâ”€â”€â–º [update] â”€â”€barrierâ”€â”€â–º
  Worker3:               â”€â”€barrierâ”€â”€â–º [update] â”€â”€barrierâ”€â”€â–º

           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                All threads work
                in parallel here

  ---
  4. Parallel Cube Processing (app_update_and_render)

  void app_update_and_render(void) {
      // Get this thread's range of cubes
      Range_u64 range = lane_range(NUM_CUBES);

      for (u64 i = range.min; i < range.max; i++) {
          CubeData *cube = &cubes[i];

          // Build model matrix
          mat4 model;
          mat4_identity(model);
          glm_translate(model, cube->position);

          f32 angle = g_time * cube->rotation_rate;
          glm_rotate(model, angle, (vec3){0, 1, 0});      // Y rotation
          glm_rotate(model, angle * 0.7f, (vec3){1, 0, 0}); // X rotation

          glm_scale_uni(model, 0.3f);  // Scale down

          // Submit draw command (thread-safe)
          renderer_draw_mesh(model);
      }
  }

  Work Distribution Example (4 threads, 1024 cubes)

  | Thread | Range    | Cubes     |
  |--------|----------|-----------|
  | 0      | 0-255    | 256 cubes |
  | 1      | 256-511  | 256 cubes |
  | 2      | 512-767  | 256 cubes |
  | 3      | 768-1023 | 256 cubes |

  Lock-Free Command Submission

  void renderer_draw_mesh(mat4 model_matrix) {
      RenderCmd cmd = {
          .type = RENDER_CMD_DRAW_MESH,
      };
      memcpy(cmd.draw_mesh.model_matrix, model_matrix, sizeof(mat4));

      // Atomic append - uses atomic_fetch_add on len_atomic
      concurrent_arr_append(g_renderer.cmds, cmd);
  }

  This is thread-safe because:
  1. len_atomic is incremented atomically to reserve a slot
  2. Each thread writes to its own reserved slot
  3. No locking needed

  ---
  5. Frame Begin (renderer_begin_frame)

  void renderer_begin_frame(mat4 view, mat4 proj, GpuColor clear_color) {
      // Store matrices for MVP computation later
      memcpy(g_renderer.view, view, sizeof(mat4));
      memcpy(g_renderer.proj, proj, sizeof(mat4));
      mat4_mul(proj, view, g_renderer.view_proj);  // Precompute view_proj

      // Reset command queue (atomic counter to 0)
      g_renderer.cmds.len_atomic = 0;

      // Reset uniform staging buffer
      gpu_uniform_reset(&g_renderer.uniforms);

      // Begin GPU render pass
      gpu_begin_pass(&(GpuPassDesc){
          .clear_color = clear_color,  // Dark blue-gray
          .clear_depth = 1.0f,
      });
  }

  On the JS side (js_gpu_begin_pass):
  js_gpu_begin_pass: (r, g, b, a, depth) => {
      currentEncoder = renderer.device.createCommandEncoder();

      const textureView = renderer.context.getCurrentTexture().createView();

      currentPass = currentEncoder.beginRenderPass({
          colorAttachments: [{
              view: textureView,
              clearValue: { r, g, b, a },
              loadOp: "clear",
              storeOp: "store",
          }],
          depthStencilAttachment: {
              view: renderer.depthTexture.createView(),
              depthClearValue: depth,
              depthLoadOp: "clear",
              depthStoreOp: "store",
          },
      });
  }

  ---
  6. Frame End (renderer_end_frame)

  This is where all the actual GPU work happens:

  void renderer_end_frame(void) {
      // 1. Set pipeline once (same for all cubes)
      gpu_apply_pipeline(g_renderer.pipeline);

      // 2. Process all queued commands
      u32 cmd_count = concurrent_arr_len(g_renderer.cmds);

      for (u32 i = 0; i < cmd_count; i++) {
          RenderCmd *cmd = concurrent_arr_get_ptr(g_renderer.cmds, i);

          if (cmd->type == RENDER_CMD_DRAW_MESH) {
              // Compute MVP = proj * view * model
              mat4 mvp;
              mat4_mul(g_renderer.view_proj, cmd->draw_mesh.model_matrix,
  mvp);

              // Allocate uniform slot in staging buffer
              u32 uniform_offset = gpu_uniform_alloc(&g_renderer.uniforms,
  mvp, sizeof(mat4));

              // Bind vertex/index buffers + uniform with dynamic offset
              gpu_apply_bindings_dynamic(
                  &(GpuBindings){
                      .vertex_buffers = {g_renderer.vbuf},
                      .vertex_buffer_count = 1,
                      .index_buffer = g_renderer.ibuf,
                      .index_format = GPU_INDEX_FORMAT_U16,
                  },
                  g_renderer.uniforms.gpu_buf,
                  uniform_offset
              );

              // Draw 36 indices (12 triangles)
              gpu_draw_indexed(36, 1);
          }
      }

      // 3. End render pass
      gpu_end_pass();

      // 4. Upload all uniforms to GPU in one batch
      gpu_uniform_flush(&g_renderer.uniforms);

      // 5. Submit command buffer
      gpu_commit();
  }

  Dynamic Uniform Buffer Detail

  u32 gpu_uniform_alloc(GpuUniformBuffer *ub, void *data, u32 size) {
      // Allocate with 256-byte alignment (WebGPU requirement)
      void *dst = arena_alloc_align(&ub->arena, size, 256);

      // Calculate offset from buffer start
      u32 offset = (u32)((u8 *)dst - ub->arena.buffer);

      // Copy MVP matrix to staging buffer
      memcpy(dst, data, size);

      return offset;  // e.g., 0, 256, 512, 768...
  }

  Memory layout for 4 cubes:
  Offset 0:    [MVP matrix 0] [padding to 256 bytes]
  Offset 256:  [MVP matrix 1] [padding to 256 bytes]
  Offset 512:  [MVP matrix 2] [padding to 256 bytes]
  Offset 768:  [MVP matrix 3] [padding to 256 bytes]

  JS Side: Dynamic Binding

  js_gpu_apply_bindings_dynamic: (bindingsPtr, uniformBufIdx, uniformOffset)
   => {
      // Read bindings from WASM memory
      const data = new Uint32Array(memory.buffer, bindingsPtr, 7);
      const vbCount = data[0];

      // Set vertex buffers
      for (let i = 0; i < vbCount; i++) {
          const buffer = buffers[data[1 + i]];
          currentPass.setVertexBuffer(i, buffer);
      }

      // Set index buffer
      currentPass.setIndexBuffer(buffers[data[5]], INDEX_FORMATS[data[6]]);

      // Get or create bind group (cached per pipeline+buffer combo)
      const key = `${currentPipelineIdx}-${uniformBufIdx}`;
      let bindGroup = pipelineUniformBindGroups.get(key);

      if (!bindGroup) {
          bindGroup = renderer.device.createBindGroup({
              layout: bindGroupLayout,
              entries: [{
                  binding: 0,
                  resource: {
                      buffer: uniformBuffer,
                      size: 256,  // One uniform slot
                  },
              }],
          });
          pipelineUniformBindGroups.set(key, bindGroup);
      }

      // Set bind group WITH DYNAMIC OFFSET
      currentPass.setBindGroup(0, bindGroup, [uniformOffset]);
  }

  The key insight: one bind group, many offsets. Instead of creating 1024
  bind groups, we create 1 and use dynamic offsets.

  ---
  7. Pipeline Creation (JS)

  js_gpu_make_pipeline: (shaderIdx, layoutPtr, primitive, depthTest, 
  depthWrite) => {
      // Read vertex layout from WASM memory
      const layoutData = new Uint32Array(memory.buffer, layoutPtr, 2 + 8 *
  3);
      const stride = layoutData[0];     // 28 bytes
      const attrCount = layoutData[1];  // 2 attributes

      // Build vertex attributes
      const attributes = [];
      for (let i = 0; i < attrCount; i++) {
          attributes.push({
              format: VERTEX_FORMATS[layoutData[2 + i * 3]],    // 
  float32x3, float32x4
              offset: layoutData[2 + i * 3 + 1],                // 0, 12
              shaderLocation: layoutData[2 + i * 3 + 2],        // 0, 1
          });
      }

      // Create bind group layout with DYNAMIC OFFSET enabled
      const bindGroupLayout = renderer.device.createBindGroupLayout({
          entries: [{
              binding: 0,
              visibility: GPUShaderStage.VERTEX,
              buffer: {
                  type: "uniform",
                  hasDynamicOffset: true,  // â† Critical for performance
              },
          }],
      });

      // Create pipeline
      const pipeline = renderer.device.createRenderPipeline({
          layout: renderer.device.createPipelineLayout({
              bindGroupLayouts: [bindGroupLayout],
          }),
          vertex: {
              module: shaderModule,
              entryPoint: "vs_main",
              buffers: [{
                  arrayStride: stride,
                  attributes,
              }],
          },
          fragment: {
              module: shaderModule,
              entryPoint: "fs_main",
              targets: [{ format: renderer.format }],
          },
          primitive: {
              topology: "triangle-list",
              cullMode: "back",
          },
          depthStencil: {
              format: "depth24plus",
              depthWriteEnabled: true,
              depthCompare: "less",
          },
      });
  }

  ---
  8. Complete Frame Data Flow

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â”
  â”‚ FRAME START
   â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â”¤
  â”‚
   â”‚
  â”‚  1. Main thread: renderer_begin_frame()
   â”‚
  â”‚     â”œâ”€ Store view/proj matrices
   â”‚
  â”‚     â”œâ”€ Reset command queue (len_atomic = 0)                             
   â”‚
  â”‚     â”œâ”€ Reset uniform staging buffer                                     
   â”‚
  â”‚     â””â”€ Begin GPU render pass (clear screen)                             
   â”‚
  â”‚                                                                         
   â”‚
  â”‚  2. BARRIER (all threads sync)                                          
   â”‚
  â”‚                                                                         
   â”‚
  â”‚  3. ALL THREADS: app_update_and_render()
   â”‚
  â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚
  â”‚     â”‚ Thread 0          Thread 1          Thread 2          Thread 3  â”‚
   â”‚
  â”‚     â”‚ cubes[0..255]     cubes[256..511]   cubes[512..767]   cubes[768.]â”‚
    â”‚
  â”‚     â”‚                                                                  â”‚
    â”‚
  â”‚     â”‚ For each cube:                                                   â”‚
    â”‚
  â”‚     â”‚   1. Build model matrix (translate, rotate, scale)               â”‚
    â”‚
  â”‚     â”‚   2. renderer_draw_mesh(model) â†’ atomic append to cmd queue      â”‚
    â”‚
  â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
  â”‚
   â”‚
  â”‚  4. BARRIER (all threads sync)
   â”‚
  â”‚
   â”‚
  â”‚  5. Main thread: renderer_end_frame()
   â”‚
  â”‚     â”œâ”€ Apply pipeline
   â”‚
  â”‚     â”œâ”€ For each command (1024 total):
   â”‚
  â”‚     â”‚   â”œâ”€ Compute MVP = view_proj * model                              
   â”‚
  â”‚     â”‚   â”œâ”€ Allocate uniform slot (returns offset 0, 256, 512...)        
   â”‚
  â”‚     â”‚   â”œâ”€ Set bindings with dynamic offset                             
   â”‚
  â”‚     â”‚   â””â”€ Draw indexed (36 indices)                                    
   â”‚
  â”‚     â”œâ”€ End render pass                                                  
   â”‚
  â”‚     â”œâ”€ Flush uniforms (single GPU upload)                               
   â”‚
  â”‚     â””â”€ Commit (submit command buffer)                                   
   â”‚
  â”‚                                                                         
   â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â”¤
  â”‚ FRAME END                                                               
   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â”˜

  ---
  9. Performance Characteristics

  | Aspect           | Implementation                         | Benefit
                         |
  |------------------|----------------------------------------|-------------
  -----------------------|
  | Multi-threading  | N threads compute matrices in parallel | Linear
  speedup for CPU work        |
  | Lock-free queue  | Atomic append to command array         | No mutex
  contention                |
  | Dynamic uniforms | Single buffer + offsets                | 1 bind group
   instead of 1024       |
  | Batched upload   | gpu_uniform_flush() at frame end       | 1
  writeBuffer call instead of 1024 |
  | Shared mesh      | Single VBO/IBO for all cubes           | Minimal
  memory, no rebinding       |
  | Single pipeline  | Same shader for all objects            | No pipeline
  switching overhead     |

  ---
  10. Memory Layout Summary

  WASM Linear Memory (SharedArrayBuffer)
  â”œâ”€â”€ Heap Base
  â”‚   â””â”€â”€ Arena (16MB)
  â”‚       â”œâ”€â”€ Uniform staging buffer (aligned to 256)
  â”‚       â”œâ”€â”€ Thread contexts Ã— N
  â”‚       â”œâ”€â”€ Worker data Ã— N
  â”‚       â”œâ”€â”€ Thread handles Ã— N
  â”‚       â””â”€â”€ Command queue (RenderCmd Ã— 1024)
  â”‚
  â”œâ”€â”€ Global Data
  â”‚   â”œâ”€â”€ cubes[1024] - CubeData (position + rotation_rate)
  â”‚   â”œâ”€â”€ g_renderer - RendererState
  â”‚   â”œâ”€â”€ g_time - frame time
  â”‚   â””â”€â”€ frame_barrier - thread synchronization
  â”‚
  â””â”€â”€ Static Data
      â”œâ”€â”€ cube_vertices[24] - mesh data
      â”œâ”€â”€ cube_indices[36] - mesh indices
      â”œâ”€â”€ cube_vs - vertex shader string
      â””â”€â”€ cube_fs - fragment shader string

> what optimization opportunities an expert rendering engineer would 
suggest? 

â— Great question. Let me analyze the current implementation and identify
  optimization opportunities across multiple categories.

  ---
  1. Instanced Rendering (Biggest Win)

  Current: 1024 individual draw calls, each with setBindGroup() +
  drawIndexed()

  Problem: Draw call overhead dominates. Each draw call has CPUâ†’GPU command
  overhead.

  Solution: Single instanced draw call

  // Instead of per-cube uniform allocation:
  // Store all matrices in a storage buffer, draw all at once

  void renderer_end_frame(void) {
      gpu_apply_pipeline(g_renderer.pipeline);

      // Upload all MVPs to storage buffer (tightly packed, no 256-byte 
  waste)
      u32 cmd_count = concurrent_arr_len(g_renderer.cmds);
      for (u32 i = 0; i < cmd_count; i++) {
          mat4 mvp;
          mat4_mul(g_renderer.view_proj,
  g_renderer.cmds.items[i].draw_mesh.model_matrix, mvp);
          memcpy(&g_renderer.mvp_buffer[i], mvp, sizeof(mat4));
      }
      gpu_update_buffer(g_renderer.mvp_storage, g_renderer.mvp_buffer,
  cmd_count * sizeof(mat4));

      // ONE draw call for all cubes
      gpu_apply_bindings(...);
      gpu_draw_indexed_instanced(36, cmd_count);  // Draw all instances
  }

  Shader change:
  struct MVPArray {
      mvps: array<mat4x4<f32>>,
  };
  @group(0) @binding(0) var<storage, read> mvp_buffer: MVPArray;

  @vertex
  fn vs_main(@builtin(instance_index) instance: u32, in: VertexInput) ->
  VertexOutput {
      var out: VertexOutput;
      out.position = mvp_buffer.mvps[instance] * vec4<f32>(in.position,
  1.0);
      out.color = in.color;
      return out;
  }

  Impact: ~1000x fewer draw calls, eliminates setBindGroup() overhead per
  cube.

  ---
  2. Eliminate 256-Byte Alignment Waste

  Current: Each 64-byte MVP matrix padded to 256 bytes (75% waste)

  [MVP 64B][padding 192B][MVP 64B][padding 192B]...

  Solution: Use storage buffer instead of uniform buffer

  // In pipeline creation:
  buffer: {
      type: "read-only-storage",  // Not "uniform"
      hasDynamicOffset: false,
  }

  Storage buffers have no alignment requirement beyond the struct itself.

  Memory: 256KB â†’ 64KB for 1024 cubes

  ---
  3. GPU-Side Matrix Computation

  Current: CPU threads compute matrices, upload to GPU

  Better: Compute shader on GPU

  struct CubeData {
      position: vec3<f32>,
      rotation_rate: f32,
  };

  @group(0) @binding(0) var<storage, read> cubes: array<CubeData>;
  @group(0) @binding(1) var<storage, read_write> mvps: array<mat4x4<f32>>;
  @group(0) @binding(2) var<uniform> frame: FrameUniforms;  // time,
  view_proj

  @compute @workgroup_size(64)
  fn compute_matrices(@builtin(global_invocation_id) id: vec3<u32>) {
      let i = id.x;
      if (i >= arrayLength(&cubes)) { return; }
      
      let cube = cubes[i];
      let angle = frame.time * cube.rotation_rate;

      // Build model matrix on GPU
      var model = mat4x4_translate(cube.position);
      model = model * mat4x4_rotate_y(angle);
      model = model * mat4x4_rotate_x(angle * 0.7);
      model = model * mat4x4_scale(0.3);

      mvps[i] = frame.view_proj * model;
  }

  Benefits:
  - Eliminates CPUâ†’GPU matrix upload (just upload cube positions once)
  - GPU parallelism far exceeds CPU thread count
  - Frees CPU threads for other work

  ---
  4. Frustum Culling

  Current: Drawing all 1024 cubes regardless of visibility

  Solution A: CPU frustum culling (simpler)
  void app_update_and_render(void) {
      Range_u64 range = lane_range(NUM_CUBES);

      for (u64 i = range.min; i < range.max; i++) {
          CubeData *cube = &cubes[i];

          // Frustum test (AABB vs 6 planes)
          if (!frustum_test_sphere(cube->position, CUBE_RADIUS)) {
              continue;  // Skip invisible cubes
          }

          // ... build matrix and submit
      }
  }

  Solution B: GPU culling with indirect draw (advanced)
  @compute @workgroup_size(64)
  fn cull_and_compact(@builtin(global_invocation_id) id: vec3<u32>) {
      let i = id.x;
      if (!frustum_test(cubes[i].position)) { return; }

      // Atomic append to visible list
      let slot = atomicAdd(&draw_args.instance_count, 1u);
      visible_indices[slot] = i;
  }

  Then use drawIndexedIndirect() with GPU-written instance count.

  ---
  5. Redundant State Setting

  Current: Every draw call sets vertex/index buffers (same for all cubes)

  for (u32 i = 0; i < cmd_count; i++) {
      gpu_apply_bindings_dynamic(...);  // Sets VB, IB, bind group EVERY 
  time
      gpu_draw_indexed(36, 1);
  }

  Fix: Set shared state once
  // Set vertex/index buffers ONCE
  gpu_set_vertex_buffer(0, g_renderer.vbuf);
  gpu_set_index_buffer(g_renderer.ibuf, GPU_INDEX_FORMAT_U16);

  for (u32 i = 0; i < cmd_count; i++) {
      // Only update what changes (uniform offset)
      gpu_set_bind_group_dynamic(0, bind_group, uniform_offset);
      gpu_draw_indexed(36, 1);
  }

  ---
  6. Per-Thread Command Buffers (Cache Optimization)

  Current: All threads append to single atomic array
  concurrent_arr_append(g_renderer.cmds, cmd);  // Atomic increment, 
  potential cache line bouncing

  Problem: Atomic len_atomic lives on one cache line, all threads contend
  for it.

  Solution: Per-thread local buffers, merge at end
  typedef struct {
      RenderCmd cmds[MAX_CMDS_PER_THREAD];
      u32 count;
  } ThreadCmdBuffer;

  global ThreadCmdBuffer thread_cmds[MAX_THREADS];

  void app_update_and_render(void) {
      u32 tid = tctx_get_current()->thread_idx;
      ThreadCmdBuffer *buf = &thread_cmds[tid];
      buf->count = 0;

      Range_u64 range = lane_range(NUM_CUBES);
      for (u64 i = range.min; i < range.max; i++) {
          // ... build matrix ...
          buf->cmds[buf->count++] = cmd;  // No atomic!
      }
  }

  // After barrier, main thread merges or processes each thread's buffer

  Benefit: Zero contention during parallel phase.

  ---
  7. Async Pipeline (CPU/GPU Overlap)

  Current: Fully synchronous frame
  CPU: [compute matrices] â†’ [upload] â†’ [encode] â†’ [submit] â†’ [wait]
  GPU:                                                        [render]

  Better: Double/triple buffering
  Frame N:   CPU: [compute N+1] [upload N+1]
             GPU:               [render N]

  Frame N+1: CPU:               [compute N+2] [upload N+2]
             GPU:                             [render N+1]

  Implementation:
  // Use multiple uniform buffers, rotate each frame
  const uniformBuffers = [createBuffer(), createBuffer(), createBuffer()];
  let frameIndex = 0;

  function frame() {
      const uploadBuffer = uniformBuffers[(frameIndex + 1) % 3];
      const renderBuffer = uniformBuffers[frameIndex % 3];

      // Upload to next frame's buffer while GPU renders current
      device.queue.writeBuffer(uploadBuffer, 0, matrixData);

      // Render with current frame's buffer
      renderPass.setBindGroup(0, bindGroups[frameIndex % 3]);

      frameIndex++;
  }

  ---
  8. Shader Optimization

  Current vertex shader:
  out.position = uniforms.mvp * vec4<f32>(in.position, 1.0);

  Consider: Separate model matrix for correct normals (if adding lighting)
  struct Uniforms {
      view_proj: mat4x4<f32>,  // Shared
      model: mat4x4<f32>,      // Per-instance
  };

  // Or for instancing with storage buffer:
  out.position = frame.view_proj * models[instance] * vec4(in.position, 
  1.0);
  out.world_normal = (models[instance] * vec4(in.normal, 0.0)).xyz;

  ---
  9. Uniform Buffer Flush Timing

  Current: Flush uniforms AFTER gpu_end_pass()
  gpu_end_pass();
  gpu_uniform_flush(&g_renderer.uniforms);  // Upload happens here
  gpu_commit();

  Problem: The render pass already encoded reads from uniform buffer
  offsets. Upload must happen before submit.

  Better: Flush BEFORE ending pass (or use staging buffer pattern)
  // Upload uniforms FIRST
  gpu_uniform_flush(&g_renderer.uniforms);

  // Then process commands (they reference already-uploaded data)
  for (u32 i = 0; i < cmd_count; i++) { ... }

  gpu_end_pass();
  gpu_commit();

  Actually, looking at the code, the current order works because writeBuffer
   happens before submit(). But it's cleaner to upload first.

  ---
  10. Multi-Draw Indirect (Advanced)

  For maximum throughput with GPU culling:

  typedef struct {
      u32 index_count;      // 36
      u32 instance_count;   // Written by GPU cull shader
      u32 first_index;      // 0
      i32 base_vertex;      // 0
      u32 first_instance;   // 0
  } DrawIndexedIndirectArgs;

  // GPU cull shader writes instance_count
  @compute @workgroup_size(1)
  fn prepare_draw() {
      draw_args.index_count = 36u;
      draw_args.instance_count = visible_count;  // From culling pass
      draw_args.first_index = 0u;
      draw_args.base_vertex = 0;
      draw_args.first_instance = 0u;
  }

  renderPass.drawIndexedIndirect(indirectBuffer, 0);

  Benefit: GPU determines draw count, zero CPU readback for culling results.

  ---
  Summary: Priority Order

  | Priority  | Optimization                       | Effort | Impact
            |
  |-----------|------------------------------------|--------|---------------
  ----------|
  | ğŸ”´ High   | Instanced rendering                | Medium | ~100x fewer
  draw calls  |
  | ğŸ”´ High   | Storage buffer (no 256B alignment) | Low    | 4x less
  memory, simpler |
  | ğŸŸ¡ Medium | Set VB/IB once                     | Low    | Fewer API
  calls         |
  | ğŸŸ¡ Medium | Per-thread cmd buffers             | Low    | Better cache
  behavior   |
  | ğŸŸ¡ Medium | Frustum culling (CPU)              | Medium | Skip invisible
   objects  |
  | ğŸŸ¢ Low    | GPU matrix compute                 | High   | Frees CPU
  entirely      |
  | ğŸŸ¢ Low    | Async/double buffer                | Medium | Better CPU/GPU
   overlap  |
  | ğŸŸ¢ Low    | Indirect draw + GPU cull           | High   | Fully
  GPU-driven        |

  The single biggest win is switching to instanced rendering. One draw call
  instead of 1024 is transformative, especially on mobile/integrated GPUs
  where draw call overhead is significant.



